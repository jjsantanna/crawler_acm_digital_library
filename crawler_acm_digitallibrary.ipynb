{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CRAWLER AND SCRAPER OF ACM DIGITAL LIBRARY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEEDED LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cfscrape\n",
    "from lxml import etree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SET OF KEYWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['DDoS attack', 'denial of service','DDoS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INSTANTIATING THE CRAWLER AND DEFINING AN REALISTIC HEADER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper = cfscrape.create_scraper()\n",
    "\n",
    "header = {'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9',\n",
    "          'Accept-Encoding': 'gzip, deflate, sdch',\n",
    "          'Accept-Language' : 'nl-NL,nl;q=0.8,en-US;q=0.6,en;q=0.4',\n",
    "          'Cache-Control' : 'max-age=0',\n",
    "          'Connection': 'keep-alive',\n",
    "          'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/12.1.2 Safari/605.1.15'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## READING OLD DATASET FOR APPENDING or CREATE A NEW (EMPTY) DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('20191001_acm_dl_ddos_papers.csv').drop(['Unnamed: 0'],axis=1)\n",
    "# df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOOP FOR CRAWLING AND SCRAPPING (IN 2 LEVELS) ALL ENTRIES RELATED TO THE SET OF KEYWORDS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for keyword in keywords:\n",
    "    page = 1 \n",
    "    while True:\n",
    "        print(page,keyword)\n",
    "        \n",
    "        keyword = keyword.replace(' ','+')\n",
    "        url = \"https://dl.acm.org/results.cfm?query=%22\"+keyword+\"%22&start=\"+str((page-1)*20)+\"&filtered=&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore\"\n",
    "        print(url)\n",
    "        \n",
    "        scraped_html=scraper.get(url,headers=header).content\n",
    "        html = etree.HTML(scraped_html)\n",
    "        \n",
    "        max_entries = html.xpath(\"//div[@class='pagerange']/text()\")[0].split()[-1]\n",
    "        if (page-1)*20 > int(max_entries):\n",
    "            break\n",
    "        \n",
    "        df_temp = pd.DataFrame()\n",
    "        \n",
    "        #Crawler first level\n",
    "        title = []\n",
    "        links = []\n",
    "        publication_date = []\n",
    "        venue=[]\n",
    "\n",
    "        for entry in html.xpath(\"//div[@class='title']/a\"):\n",
    "            try:\n",
    "                title.append(entry.xpath(\"text()\")[0])\n",
    "            except:\n",
    "                title.append(\"\")\n",
    "\n",
    "            try: \n",
    "                links.append('https://dl.acm.org/'+entry.xpath(\"@href\")[0]+'&preflayout=flat')\n",
    "            except:\n",
    "                links.append(\"\")\n",
    "\n",
    "        for entry in html.xpath(\"//div[@class='source']\"): \n",
    "            try:\n",
    "                publication_date.append(entry.xpath(\"span[@class='publicationDate']/text()\")[0])\n",
    "            except:\n",
    "                publication_date.append(\"\")\n",
    "\n",
    "            try:\n",
    "                venue.append(entry.xpath(\"span[@style='padding-left:10px']/text()\")[0])\n",
    "            except:\n",
    "                venue.append(\"\")\n",
    "\n",
    "        df_temp = pd.DataFrame({'title': title,'links': links,'publication_date': publication_date,'venue': venue,})\n",
    "    \n",
    "        #Crawler second level\n",
    "        for link in df_temp['links']:\n",
    "            print(link)\n",
    "            # CHECK IF THE LINK ALREADY EXIST\n",
    "            if len(df[df['links']==link]) >0:\n",
    "                df_temp.drop(df_temp.loc[df_temp['links']==link].index, inplace=True)\n",
    "                print(\"duplicated\")\n",
    "                continue\n",
    "                \n",
    "            \n",
    "            scraped_html=scraper.get(link,headers=header).content\n",
    "            html = etree.HTML(scraped_html)\n",
    "\n",
    "            index_current = df_temp.index[df_temp['links'] == link][0]\n",
    "\n",
    "            try:\n",
    "                df_temp.at[index_current, 'link4download'] = \"https://dl.acm.org/\" + html.xpath(\"//table[@class='medium-text']/tr/td/a/@href\")[0]\n",
    "            except:\n",
    "                df_temp.at[index_current, 'link4download'] = \"\"\n",
    "\n",
    "            try:\n",
    "                df_temp.at[index_current, 'num_citations'] = [x for x in html.xpath(\"//table[@class='medium-text']/tr/td[@class='small-text']/text()\") if 'Citation' in x][0].replace('\\n','').replace('路\\xa0','').replace('Citation Count: ','')\n",
    "            except:\n",
    "                df_temp.at[index_current, 'num_citations'] =\"\"\n",
    "\n",
    "            try:\n",
    "                df_temp.at[index_current, 'num_downloads_cu'] = [x for x in html.xpath(\"//table[@class='medium-text']/tr/td[@class='small-text']/text()\") if 'Downloads (cumulative)' in x][0].replace('\\n','').replace('路\\xa0','').replace('Downloads (cumulative): ','')\n",
    "            except:\n",
    "                df_temp.at[index_current, 'num_downloads_cu'] =\"\"\n",
    "\n",
    "            try:\n",
    "                df_temp.at[index_current, 'abstract'] = html.xpath(\"//div[@style='display:inline']/p/text()\")[0]\n",
    "            except:\n",
    "                try: \n",
    "                    df_temp.at[index_current, 'abstract'] = html.xpath(\"//div[@style='display:inline']/text()\")[0]\n",
    "                except:\n",
    "                    try:\n",
    "                        df_temp.at[index_current, 'abstract'] = html.xpath(\"//div[@class='flatbody']/div/text()\")[0].replace('\\n','')\n",
    "                    except:\n",
    "                        df_temp.at[index_current, 'abstract'] = \"\"\n",
    "        \n",
    "        df = df.append(df_temp,ignore_index=True)\n",
    "        display(df.tail(1))\n",
    "        \n",
    "        page = page + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAVING FINDINGS TO PROCESS OFFLINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('20191001_acm_dl_ddos_papers.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEBUGGING ERROS 1ST LEVEL CRAWLER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://dl.acm.org/results.cfm?query=%22denial+of+service%22&start=300&filtered=&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_html=scraper.get(url,headers=header).content\n",
    "print(scraped_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = etree.HTML(scraped_html)\n",
    "\n",
    "df_temp = pd.DataFrame()\n",
    "title = []\n",
    "links = []\n",
    "publication_date = []\n",
    "venue=[]\n",
    "\n",
    "for entry in html.xpath(\"//div[@class='title']/a\"):\n",
    "    try:\n",
    "        title.append(entry.xpath(\"text()\")[0])\n",
    "    except:\n",
    "        title.append(\"\")\n",
    "    \n",
    "    try: \n",
    "        links.append('https://dl.acm.org/'+entry.xpath(\"@href\")[0]+'&preflayout=flat')\n",
    "    except:\n",
    "        links.append(\"\")\n",
    "\n",
    "for entry in html.xpath(\"//div[@class='source']\"): \n",
    "    try:\n",
    "        publication_date.append(entry.xpath(\"span[@class='publicationDate']/text()\")[0])\n",
    "    except:\n",
    "        publication_date.append(\"\")\n",
    "    \n",
    "    try:\n",
    "        venue.append(entry.xpath(\"span[@style='padding-left:10px']/text()\")[0])\n",
    "    except:\n",
    "        venue.append(\"\")\n",
    "\n",
    "df_temp = pd.DataFrame({'title': title,'links': links,'publication_date': publication_date,'venue': venue,})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEBUGING ERROS 2nd LEVEL CRAWLER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = \"https://dl.acm.org/citation.cfm?id=372148&preflayout=flat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_html=scraper.get(link,headers=header).content\n",
    "print(scraped_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = etree.HTML(scraped_html)\n",
    "\n",
    "df_temp = pd.DataFrame()\n",
    "index_current = 0\n",
    "\n",
    "try:\n",
    "    df_temp.at[index_current, 'link4download'] = \"https://dl.acm.org/\" + html.xpath(\"//table[@class='medium-text']/tr/td/a/@href\")[0]\n",
    "except:\n",
    "    df_temp.at[index_current, 'link4download'] = \"\"\n",
    "\n",
    "try:\n",
    "    df_temp.at[index_current, 'num_citations'] = [x for x in html.xpath(\"//table[@class='medium-text']/tr/td[@class='small-text']/text()\") if 'Citation' in x][0].replace('\\n','').replace('路\\xa0','').replace('Citation Count: ','')\n",
    "except:\n",
    "    df_temp.at[index_current, 'num_citations'] =\"\"\n",
    "\n",
    "try:\n",
    "    df_temp.at[index_current, 'num_downloads_cu'] = [x for x in html.xpath(\"//table[@class='medium-text']/tr/td[@class='small-text']/text()\") if 'Downloads (cumulative)' in x][0].replace('\\n','').replace('路\\xa0','').replace('Downloads (cumulative): ','')\n",
    "except:\n",
    "    df_temp.at[index_current, 'num_downloads_cu'] =\"\"\n",
    "\n",
    "try:\n",
    "    df_temp.at[index_current, 'abstract'] = html.xpath(\"//div[@style='display:inline']/p/text()\")[0]\n",
    "except:\n",
    "    try: \n",
    "        df_temp.at[index_current, 'abstract'] = html.xpath(\"//div[@style='display:inline']/text()\")[0]\n",
    "    except:\n",
    "        try:\n",
    "            df_temp.at[index_current, 'abstract'] = html.xpath(\"//div[@class='flatbody']/div/text()\")[0].replace('\\n','')\n",
    "        except:\n",
    "            df_temp.at[index_current, 'abstract'] = \"\"\n",
    "\n",
    "df_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align='center'>###############################################################<br>###############################################################<br>OFFLINE PROCESSING!!!</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## READING THE DATAFRAME "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('20191001_acm_dl_ddos_papers.csv').drop(['Unnamed: 0'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUICK PREVIEW OF THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ISOLATING THE ID IN A COLUMN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['id'] = df['links'].apply(lambda x: x.replace(\"https://dl.acm.org/citation.cfm?id=\",\"\").replace(\"&preflayout=flat\",\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATING SOME EMPTY COLUMNS FOR MANUAL CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dm']=\"\"\n",
    "df['attack_type']= \"\"\n",
    "df['defence_deployment']=\"\"\n",
    "df['not_attack_type']=\"\"\n",
    "df['attack_impact']=\"\"\n",
    "df['attack_infra']=\"\"\n",
    "df['overview']= \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPORTING COLUMNS TO CSV FOR MANUAL CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['id','abstract','overview','dm','attack_type','defence_deployment','attack_infra','attack_impact','not_attack_type']].to_excel('abstracts4classifying.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
